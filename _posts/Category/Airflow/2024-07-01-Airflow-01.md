---
layout:     BLACKCODE
title: "Airflow 설치 및 배포"
subtitle:   ""
description: ""
date: 2024-07-01 01:00:00 +0900
author:     "김민서"
header-img: "assets/owner/hero/home-bg.jpg"
header-video: "assets/video/metrix.mp4"
thumbnail: /assets/owner/blog/thumbs/thumb01.png
tags: [AI]
category: [AIRFLOW]
# comments: false
# share: false
---

# 1. Airflow 설치를 위한 사전 준비
## 1. 사전 준비
- Azure VM
    - 웹 포트 설정 : 7070
    - OS : Ubuntu 20.04LTS
- Python

## python 설치
파이썬 버전 확인
```shell
python3 --version
```

## 2. 가상 환경 생성 (선택 사항)
가상 환경을 사용하면 프로젝트별로 패키지를 관리할 수 있습니다.
```shell
python3 -m venv airflow_venv
source airflow_venv/bin/activate
```

# 2. Apache Airflow 설치
## 1. Airflow 패키지 설치
Airflow는 PyPI(Python Package Index)에서 설치할 수 있습니다. Airflow는 여러 플러그인과 추가 기능을 포함할 수 있어, 특정 필요에 따라 설치할 패키지를 선택할 수 있습니다. 여기서는 기본 설치 방법을 소개합니다.

```shell
pip install apache-airflow
```

Airflow의 특정 버전을 설치하려면 다음과 같이 할 수 있습니다.

```shell
pip install apache-airflow==2.5.1
```

## 2. Airflow 초기화
Airflow를 처음 설치한 후에는 데이터베이스를 초기화해야 합니다. Airflow는 SQLite 데이터베이스를 기본으로 사용합니다.
```shell
airflow db init
```

## 3. Airflow 구성파일
1. Airflow 구성파일
Airflow의 기본 설정 파일은 ~/airflow/airflow.cfg에 있습니다. 필요에 따라 이 파일을 수정할 수 있습니다. 예를 들어, 데이터베이스 연결 설정이나 기타 환경 설정을 변경할 수 있습니다.
2. 환경 변수 설정
Airflow는 여러 환경 변수를 사용합니다. 환경 변수를 설정하여 Airflow를 구성할 수 있습니다. 가장 중요한 환경 변수는 AIRFLOW_HOME입니다
```shell
export AIRFLOW_HOME=/home/<user>/<Airflow 설치경로>
```

## 4 Airflow 실행
1. Airflow 웹 서버 시작
```shell
airflow webserver -p 7070
```
웹 서버가 시작되면, 웹 브라우저에서 http://localhost:7070으로 접속하여 Airflow UI를 확인할 수 있습니다.
2. Airflow 스케줄러 시작
```shell
airflow scheduler
```
Airflow 스케줄러는 DAG(Directed Acyclic Graph)를 스케줄링하고 실행합니다.
스케줄러를 별도의 터미널에서 실행하면, DAG가 정의된 스케줄에 따라 실행됩니다.

## 5. DAG 작성 및 테스트
1. DAG 디렉토리
Airflow의 기본 DAG 디렉토리는 ~/airflow/dags입니다. 이 디렉토리에 DAG 파일을 작성하여 추가할 수 있습니다.
2. DAG 예제 파일
다음은 간단한 DAG 예제 파일입니다. ~/airflow/dags 디렉토리에 example_dag.py 파일을 생성합니다.


```python
from airflow import DAG
from airflow.operators.dummy import DummyOperator
from datetime import datetime

default_args = {
    'owner': 'airflow',
    'start_date': datetime(2023, 1, 1),
    'retries': 1,
}

dag = DAG(
    'example_dag',
    default_args=default_args,
    schedule_interval='@daily',
)

start = DummyOperator(
    task_id='start',
    dag=dag,
)

end = DummyOperator(
    task_id='end',
    dag=dag,
)

start >> end
```

## 6. 추가 구성 및 플러그인 설치 (선택 사항)
Airflow는 다양한 플러그인과 추가 기능을 제공합니다. 필요에 따라 추가 패키지를 설치할 수 있습니다. 예를 들어, AWS와의 통합을 위해 apache-airflow[amazon] 패키지를 설치할 수 있습니다.
```shell
pip install apache-airflow[amazon]
```

## 7. 마무리
이제 Airflow가 성공적으로 설치되고 기본 설정이 완료되었습니다. Airflow UI를 통해 DAG를 관리하고 모니터링할 수 있습니다. 필요에 따라 추가 구성과 튜닝을 진행할 수 있습니다.